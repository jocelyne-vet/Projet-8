{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f21bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.databricks.com/_static/notebooks/deep-learning/deep-learning-transfer-learning-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa26d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SQLContext\n",
    "import os \n",
    "# from pyspark.context import SparkContext\n",
    "# # Get a reference to the Spark Session\n",
    "# sc = SparkContext()\n",
    "# spark = SparkSession(sc)\n",
    "\n",
    "\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "        .appName('PySpark_Fruits')\\\n",
    "        .config(\"spark.driver.memory\", \"16g\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "#sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9efa0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split, udf\n",
    "\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fcb258",
   "metadata": {},
   "source": [
    "Charger la dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08171b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[image: struct<origin:string,height:int,width:int,nChannels:int,mode:int,data:binary>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"Fruit-Images/\"\n",
    "images = spark.read.format(\"image\") \\\n",
    "  .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "  .option(\"recursiveFileLookup\", \"true\") \\\n",
    "  .load(path)\n",
    "\n",
    "display(images.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e0e2c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1489a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.withColumn('label',element_at(split(images['image.origin'],\"/\"),-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "101d3698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbfcec9",
   "metadata": {},
   "source": [
    "Préparation du modèle : Chargement du modèle sans la dernière couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66611e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights=None, include_top=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f151d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyspark import SparkContext\n",
    "#SparkContext.setSystemProperty('spark.executor.memory', '32g')\n",
    "\n",
    "bc_model_weights = sc.broadcast(model.get_weights())# utilisation de variables de diffusion\n",
    "\n",
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a VGG16 model with top layer removed and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = VGG16(weights=None, include_top=False)\n",
    "    model.set_weights(bc_model_weights.value)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d867d07c",
   "metadata": {},
   "source": [
    "* featurize a pd.Series of images\n",
    "    * preprocess une image\n",
    "    \n",
    "utilisation de Scalar Iterator pandas pour amortir le coût du chargement\n",
    "de gros models sur les \"workers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba13d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path_file):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    path_file = path_file.replace(\"file://\", \"\")\n",
    "    img = load_img(path_file)\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)\n",
    "\n",
    "def featurize_series(model, path_series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the input model.\n",
    "    :return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(path_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2258f59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jo/anaconda3/lib/python3.8/site-packages/pyspark/sql/pandas/functions.py:389: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf('array<Double>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(path_series_iter):\n",
    "    '''\n",
    "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
    "  \n",
    "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
    "                              is a pandas Series of image data.\n",
    "    '''\n",
    "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
    "    model = model_fn()\n",
    "    for path_series in path_series_iter:\n",
    "        yield featurize_series(model, path_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dd86687",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = images.repartition(16).select(col(\"image.origin\"), col(\"label\"), featurize_udf(\"image.origin\").alias(\"features\"))\n",
    "#features_df = images.withColumn('features', featurize_udf('image')).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "036206d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- origin: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa52838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+\n",
      "|              origin|         label|            features|\n",
      "+--------------------+--------------+--------------------+\n",
      "|file:///home/jo/P...|       Avocado|[0.0, 0.169608205...|\n",
      "|file:///home/jo/P...|       Avocado|[0.0, 0.267576307...|\n",
      "|file:///home/jo/P...|Apple_Braeburn|[0.0, 0.362186431...|\n",
      "|file:///home/jo/P...|       Avocado|[0.0, 0.160421162...|\n",
      "|file:///home/jo/P...|       Apricot|[0.0, 0.258375674...|\n",
      "|file:///home/jo/P...|Apple_Braeburn|[0.0, 0.330986350...|\n",
      "|file:///home/jo/P...|       Apricot|[0.0, 0.281262934...|\n",
      "|file:///home/jo/P...|       Apricot|[0.0, 0.279605954...|\n",
      "|file:///home/jo/P...|       Avocado|[0.0, 0.174274235...|\n",
      "|file:///home/jo/P...|       Apricot|[0.0, 0.321444869...|\n",
      "|file:///home/jo/P...|Apple_Braeburn|[0.0, 0.335478305...|\n",
      "+--------------------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cab0675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[0.0, 0.174274235...|\n",
      "+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_df.select('features').show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a726b1d",
   "metadata": {},
   "source": [
    "# Réduction de dimension des features extraites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c052c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vector_udf = udf(lambda a: Vectors.dense(a), VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1802b14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1a63c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = features_df.select(to_vector_udf(\"features\").alias(\"features_vec\"))\n",
    "data = features_df.withColumn(\"features_vec\", to_vector_udf(\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7718e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- origin: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- features_vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "348601c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+--------------------+\n",
      "|              origin|         label|            features|        features_vec|\n",
      "+--------------------+--------------+--------------------+--------------------+\n",
      "|file:///home/jo/P...|       Avocado|[0.0, 0.169608205...|[0.0,0.1696082055...|\n",
      "|file:///home/jo/P...|       Avocado|[0.0, 0.267576307...|[0.0,0.2675763070...|\n",
      "|file:///home/jo/P...|Apple_Braeburn|[0.0, 0.362186431...|[0.0,0.3621864318...|\n",
      "|file:///home/jo/P...|       Avocado|[0.0, 0.160421162...|[0.0,0.1604211628...|\n",
      "|file:///home/jo/P...|       Apricot|[0.0, 0.258375674...|[0.0,0.2583756744...|\n",
      "|file:///home/jo/P...|Apple_Braeburn|[0.0, 0.330986350...|[0.0,0.3309863507...|\n",
      "|file:///home/jo/P...|       Apricot|[0.0, 0.281262934...|[0.0,0.2812629342...|\n",
      "|file:///home/jo/P...|       Apricot|[0.0, 0.279605954...|[0.0,0.2796059548...|\n",
      "|file:///home/jo/P...|       Avocado|[0.0, 0.174274235...|[0.0,0.1742742359...|\n",
      "|file:///home/jo/P...|       Apricot|[0.0, 0.321444869...|[0.0,0.3214448690...|\n",
      "|file:///home/jo/P...|Apple_Braeburn|[0.0, 0.335478305...|[0.0,0.3354783058...|\n",
      "+--------------------+--------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f80dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(k = 20, inputCol = \"features_vec\", outputCol = \"pca_features\")\n",
    "model_pca = pca.fit(data)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eee9fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca = model_pca.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a37a099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance : [7.23664847e-01 1.56294859e-01 6.40149215e-02 4.62250302e-02\n",
      " 2.44079202e-03 2.28387174e-03 1.61655465e-03 1.59219006e-03\n",
      " 1.10494227e-03 7.61991792e-04 3.34184301e-15 3.27394673e-15\n",
      " 2.59118532e-15 2.52493543e-15 2.33346653e-15 1.94300725e-15\n",
      " 1.91356255e-15 1.86212006e-15 1.47902141e-15 1.37326795e-15]\n"
     ]
    }
   ],
   "source": [
    "print('Explained Variance :', model_pca.explainedVariance.toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f09b07ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "|              origin|         label|            features|        features_vec|        pca_features|\n",
      "+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "|file:///home/jo/P...|       Avocado|[0.0, 0.169608205...|[0.0,0.1696082055...|[19.5446212229797...|\n",
      "|file:///home/jo/P...|       Avocado|[0.0, 0.267576307...|[0.0,0.2675763070...|[13.0136398313400...|\n",
      "|file:///home/jo/P...|Apple_Braeburn|[0.0, 0.362186431...|[0.0,0.3621864318...|[12.7893440303211...|\n",
      "|file:///home/jo/P...|       Avocado|[0.0, 0.160421162...|[0.0,0.1604211628...|[19.5005920854939...|\n",
      "|file:///home/jo/P...|       Apricot|[0.0, 0.258375674...|[0.0,0.2583756744...|[12.4264792738997...|\n",
      "|file:///home/jo/P...|Apple_Braeburn|[0.0, 0.330986350...|[0.0,0.3309863507...|[12.8213011577409...|\n",
      "+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_pca.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6195168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ecriture du dataframe dans un fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2193add1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- origin: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- features_vec: vector (nullable = true)\n",
      " |-- pca_features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_pca.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e0e650d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.functions import vector_to_array\n",
    "data_pca = data_pca.withColumn('pca_features_list',vector_to_array('pca_features'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb966df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_arr_list(x):\n",
    "    return x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8090ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "udf_conv_arr_list = udf(conv_arr_list, ArrayType(FloatType()))\n",
    "udf_vector_to_array = udf(lambda v:v.toArray().tolist(),ArrayType(FloatType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b607729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- origin: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- pcaFeaturesList: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_write = data_pca.select('origin','label', udf_vector_to_array('pca_features').alias('pcaFeaturesList'))\n",
    "df_write.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b7fe89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:41337)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jo/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\", line 977, in _get_connection\n",
      "    connection = self.deque.pop()\n",
      "IndexError: pop from an empty deque\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jo/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1115, in start\n",
      "    self.socket.connect((self.address, self.port))\n",
      "ConnectionRefusedError: [Errno 111] Connection refused\n"
     ]
    },
    {
     "ename": "Py4JNetworkError",
     "evalue": "An error occurred while trying to connect to the Java server (127.0.0.1:41337)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakefile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ce77d84b2f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_write\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fruits.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataFrameWriter\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \"\"\"\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrameWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    883\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjsq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1029\u001b[0m          \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \"\"\"\n\u001b[0;32m-> 1031\u001b[0;31m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m_create_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    983\u001b[0m         connection = GatewayConnection(\n\u001b[1;32m    984\u001b[0m             self.gateway_parameters, self.gateway_property)\n\u001b[0;32m--> 985\u001b[0;31m         \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 \u001b[0;34m\"server ({0}:{1})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1127\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_authenticate_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JNetworkError\u001b[0m: An error occurred while trying to connect to the Java server (127.0.0.1:41337)"
     ]
    }
   ],
   "source": [
    "df_write.write.parquet('fruits.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "df9f3988",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "CSV data source does not support array<float> data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-19c9e2e70760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_write\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fruits.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m   1370\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m                        encoding=encoding, emptyValue=emptyValue, lineSep=lineSep)\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0morc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitionBy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: CSV data source does not support array<float> data type."
     ]
    }
   ],
   "source": [
    "df_write.write.mode(\"overwrite\").csv('fruits.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6df28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
